---
title: "A/B Test in observational setting"
last_modified_at: 2016-03-09T16:21:02-05:00
mathjax: true
toc: true
categories:
  - Blog
tags:
  - Bayesian
  - probability
  - standard
---


The majority of consultations at Wiseyak are for the most typical statistical challenge in business, which is choosing between various variants of advertisements, plans, flavors, or campaigns and comparing them to specific metrics. The Business can then decide which is better and quickly capitalize on its investments based on its decision.

It is generally known that this type of study is frequently carried out in an experimental setting, where it is assumed that all the data obtained has been correctly randomized (which frequently doesn't happen). However, we will be using data from observational settings in this article. Observational data has numerous benefits, including being readily available, less expensive to gather as these are embedded into the system, and serving as a good framework for decision theory.[Maximilian Kasy,2016](https://scholar.harvard.edu/files/kasy/files/experimentaldesign.pdf)
                 
## Purpose
One of the key strategies for every food and FMCG firm is to diversify its flavors. To meet the diversity in the people and their tastes, these sorts of diversity are necessary. Therefore, measures used to increase flavor diversity not only keep consumers interested in brands and trends but also satiate any untapped market.  For Instance; With its "Hami Sabaiko Wai Wai" slogan, which aims to include all members of the Nepalese community, Waiwai noodles a popular noodle brand in Nepal come in more than 10 different tastes.
In this article, we will be comparing two variants of  Flavors (i.e A or B) based on the observed sales data to recommend any change in bad performing Flavor.

### Data
We have reported sales and stock data after three months of delivery from each dealer around the nation.
<div class="center" > <img src="https://raw.githubusercontent.com/roesta07/wiseletters/master/assets/images/ab-test-1/flav.jpg" width="300" class="inline"> </div>

Fig: Data-set (first 8 entries)
- flavor: flavors (A and B) codded as 0 or 1
- Stock: remaining units of product on stock.
- Sold: units sold
- Total: total units sent at the first place.
- Dealer: dealer ids.



## Methods and Workflow

### Naive approach
<div class="center" > <img src="https://raw.githubusercontent.com/roesta07/wiseletters/master/assets/images/ab-test-1/dag-naive.PNG" width="500" class="inline"> </div>

<p class="figureName" >*Fig: Which F (Flavours-A or B) cause S(Sales) * </p>

We can compare two flavors by estimating which flavours causes more sales. Running a simple Logistic regression and testing the impact of the different flavors on sales is naive and ignorant. Later, I'll explain why we refer to this as a Naive method, but for now, let's run the regression to find out. You can use any program of your choice to run this. In this case, we'll use Bayesian techniques to perform a Bayesian logistic regression. 

#### Naive conclusion
After running logistic regression on our desired software, we get an output similar to the below, but since we did it in a bayesian setting  we received the entire distribution rather than just the means.

<div class="center" > <img src="https://raw.githubusercontent.com/roesta07/wiseletters/master/assets/images/ab-test-1/diff_flavors_naive.jpeg" width="300" class="inline"> 
<img  src="https://raw.githubusercontent.com/roesta07/wiseletters/master/assets/images/ab-test-1/affect_flavour.png" width="250" class="inline"> 
</div>

We can see that Flavour-B contributes around 13\% more than Flavour-A to sales. Assuming this model is true; we will be reporting to our Food technicians; we require a serious change in Flavour A. But then we would be wrong; why? Because a lot of things could contribute to this effect and since we haven't measured and adjusted for those factors and ignoring these can lead to incorrect inference about the difference in Flavor; we will look into this in detail next.

### What’s Wrong with Naïve Approach

Let’s look at our context and gaze into the problem:
<div class="center" > <img src="https://raw.githubusercontent.com/roesta07/wiseletters/master/assets/images/ab-test-1/nepal.jpg" width="500" class="inline"> 
<p> Fig: Distributed Dealer Around the Nation} </p>
</div>

#### Ignores Theory
 Each dealer's locations are in different regions and each region has different cultures and taste preferences. In some regions, it's hard to sell anything regardless of the difference in flavor yet these regions have a preference for a certain flavor. This causes certain regions to stock more of one particular flavor but since the region itself is in some geography that it’s harder for both flavors to be sold; in other words, their baseline sales are lower despite any flavor, and since the supply is not fixed and are determined by the market we see this kind of heterogeneity.

If we could incorporate this geographical data and condition them by regions, we might be able to might get closer to truth estimates. As we begin adjusting for more factors in our model, the estimates for the effects shift or even reverse. This kind of phenomenon is purely a statistical phenomenon, and [Simpson Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox) is the name given to this type of phenomenon.
Even though for any company it's easy to get regional or dealer geographical information; to make the example more challenging let’s assume we have no measure for those adjustments.

#### Ignores Over-Dispersion
These unaccounted factors cause some data points to become very influential to the naïve model. These are often considered Outliers but since these are the part of data generative process, the data set becomes Over-Dispersed.
These influential spots can be calculated mathematically utilizing PSIS (Pareto-Smoothed Importance Sampling ) and WAIC (Watanabe–Akaike information criterion). It's okay that the readers don't have to understand these metrics to get the gist of this article but t hese metrics are merely one that measures the impact of these outliers which uses Kl Divergences behind the scenes.
Let’s look at our context and gaze into the problem:
<div class="center" > <img src="https://raw.githubusercontent.com/roesta07/wiseletters/master/assets/images/ab-test-1/outliers.png" width="500" class="inline"> 
<p> Fig: Influential Points (Right-side)-Checking Outliers </p>
</div>
All the points that are on the right side of the dashed line are highly influential data points for the naive model; These are the regions where baseline sales are low with imbalanced or higher supplies. And our Naive Model is highly influenced by these points which drive those estimates towards them.


###  Calibrated Approach (Beta-Binomial)
Here at Wiseyak; we always try to make the model more calibrated (look *Further Notes* at the end of this article). Since our data has heterogeneity; for each observation, now we assume it has now a different distribution of p (probability of success). Now we are estimating the distributions of probability of success instead of a single probability of success. Here in the context of this example; we say that each observation’s probability of sales for each flavor has its distribution.

For this, we use Beta-Binomial Distribution which is a family continuous Mixture Model which can incorporate this kind of heterogeneity by the above-mentioned assumption. Let’s look at the specs of the Beta-binomial model.

$$S_{i}\sim BetaBinomial(N_{i},\mu[Fid],\kappa)$$

$$\mu \sim Beta(2,2) $$

$$\kappa = 2+\phi$$

$$\phi \sim Exponential(1) $$

We assume that the sold units come from Beta-Binomial Distribution and for each observation, the distribution of the probability of success comes from Beta Distribution. We use Beta Distribution because there is a sweet analytical solution that makes the posterior easier to compute. We also provide Beta Prior to mu with alpha and beta of 2.

Another way to describe Beta distribution is with average probability($$/mu$$) and $$\kappa$$ which is the shape parameter. To understand $$\kappa$$ and others assigned prior; let's do a Prior predictive simulation.

#### PRIOR PREDICTIVE SIMULATION

It's always a good idea to do Prior predictive simulations for these kinds of Generalized Linear Models(GLMs) because the parameters tend to interact on an output level. Also, it's always a good practice in Bayesian Statistics to include this kind of simulation. Here at wiseyak, we try to follow a proper  Bayesian Workflow for this kind of analysis. Since we are estimating distributions of distributions, let's plot those expected distributions before we even see the data.

Here we have to add some extra information to the model manually to estimate the dispersion since we do not have enough data to calculate the dispersion parameter all by itself. Let's look at the plot below to understand what this means with the Simulation.

<div class="center" > <img src="https://raw.githubusercontent.com/roesta07/wiseletters/master/assets/images/ab-test-1/prior_simulations.png" width="500" class="inline"> 
<p> Fig: Prior Predictive Simulation
</p>
</div>

If we look at the right model, most of the mean of the probability of success lies at 0 or 1 which is unlikely given our system. Therefore we will select the left model for the prior. Here $$\kappa = \phi + 2$$ ; and since $$\phi \sim Exponential(1)$$ , $$\phi$$  will always be positive thus we will be sampling  $$\kappa$$ which will always be greater than 2. When $$\kappa$$ is more than 2 every probability from 0 to 1 is equally likely.


### Calibrated Report

<div class="center" > <img src="https://raw.githubusercontent.com/roesta07/wiseletters/master/assets/images/ab-test-1/model2_summary.PNG" width="280" class="inline"> 
<img  src="https://raw.githubusercontent.com/roesta07/wiseletters/master/assets/images/ab-test-1/difference.png" width="250" class="inline"> 
<p> Fig: Left: Beta-Binomial Model(Calibrated Model) Summary; Right: difference of Flavor 1 over 1 (diff parameter from the table)
</p>

</div>

We can conclude that the preferences for the two flavors are not different from each other. If you look at the plot in the right the difference is centered around zero. The problem may be due to the distribution channels but requires more analysis on that.

### Model Comparison

<div class="center" > <img src="https://raw.githubusercontent.com/roesta07/wiseletters/master/assets/images/ab-test-1/comparision.png" width="500" class="inline"> 
<p> Fig: Prior Predictive Simulation
</p>
</div>

There are different ways to compare models; at wise yak, we use WAIC (Watanabe–Akaike information criterion) for these kinds of models;  it uses Kl-divergences behind its equation to measure the distance between two or more models deviance is just some transformation of such distance; so that the lower deviance signifies better models. Here Dispersed Model outperforms the naive model;  as we can see its deviance is lower.


#### *Further Notes*
Note that even though our models can be calibrated our decision does not have to be; the calibration was important so that we don't get surprised by less likely events and incorporate those while making any decision. Back to our example, we can add in the cost of implementing each flavor and output revenue just by using the above model and aiming for a certain goal; these are within the bounds of decision theory which is a branch of applied probability theory and so is our model above. At Wiseyak; we follow these kinds of calibrated approaches for any decision theory problems; further, these kinds of models can be improved by using Multilevel-Models which are more robust to heterogeneity in the data.


#### A note on Heterogeneity in the data

The heterogeneity in the data is omnipresent in these kinds of observational studies. These can arise due to many factors like confounding, omitted variables, and others that can affect the relationship that we are interested in. And to overcome these we need to adjust for all of those but we haven’t measured all of those, and the fact that we haven’t measured them does not mean that it’s not there. We need a criterion to overcome such bias.

To overcome these kinds of heterogeneity always we need to think beyond the data-set itself these require gathering information from the Experts or understanding the process or using theory and incorporating it into the model.


In this study, we are working with data from observational settings. Few reasons that we often work with observational data are as follows:

- Observational data are easily accessible; these might be the data recorded by an organization on a daily, weekly, or monthly basis. These are just plain observations.
- A good randomized experiment requires a lot of money to run. Also in many cases, randomized experiments are unethical to run.
\item Additionally, we seek outcomes based on those differences in addition to differences themselves, randomized experiments is not a useful framework for decision theory. [Maximilian Kasy,2016](https://scholar.harvard.edu/files/kasy/files/experimentaldesign.pdf)

- Occasionally, while using experimental designs, we are unsure if we have correctly randomized our experiment (this is typically caused by a lack of theory and poor study designs), and this may undermine our ability to draw conclusions. In that situation, we might additionally need to use the techniques listed below.
